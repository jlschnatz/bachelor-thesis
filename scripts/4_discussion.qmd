---
bibliography: ../bibliography/tidy_references.bib
---

# General Discussion

The objective of the present thesis was to introduce a flexible simulation-based framework, to assess the extent of publication bias and estimate corrected effect sizes based on the joint distribution of effect size and sample size in the presence of publication bias (SPEEC). In a proof-of-concept study, the viability of the SPEEC method was evaluated through four theoretically justified hypotheses, which were should be corroborated by empirical data encompassing both classical meta-analyses and publication bias-free registered replication reports (RRRs) if the method works in principle. The confirmatory analyses revealed that, while three out of the four predictions were statistically significant, the effect sizes for these hypotheses were weak. Additionally, no evidence supported the fourth hypothesis pointing to potential issues with the parameter estimation in the SPEEC method.

To further diagnose these potential parameter estimation challenges, five exploratory diagnostic questions were derived, using the subset of publication bias-free RRRs to compare the distributional parameters estimated using SPEEC to those estimated using Maximum Likelihood Estimation (MLE). Additionally, it was examined how these divergences between SPEEC and MLE are associated with the publication bias parameter $\pbs$ and uncertainty-related factors such as the meta-analytical sample size $k$ and between-study heterogeneity $\tau$. Overall, this analysis aimed to quantify the extent and consistency of misestimations in SPEEC compared to MLE (questions 1-3) and to identify potential root causes of the parameter estimation issues (questions 4-5).

## Extent and Consistency of Misestimation of SPEEC Parameters

Regarding the first three exploratory diagnostic questions, it was found that, except for the mean $\mu_d$ of the effect size distribution, there were *systematic* divergences between SPEEC and MLE in the parameter estimation. This misestimation of SPEEC from MLE was not constant across the parameter space of the MLE estimates, displaying nonlinear functional forms and substantial heteroscedasticity. 

The correlational analyses indicated a consistency in the misestimation of SPEEC compared to MLE for the mean $|\Delta_{\widehat{\mu}_d}|$ and variance parameter $|\Delta_{\widehat{\sigma}^2_d}|$ of the effect size distribution. In other words, an increase in the absolute divergence between SPEEC and MLE in one parameter was associated with an increase in the absolute divergence in the other parameter. The absence of any substantial (and significant) correlations between the divergences of SPEEC and MLE for effect size distribution parameters ($|\Delta_{\widehat{\mu}_d}|$, $|\Delta_{\widehat{\sigma}^2_d}|$) and sample size distribution parameters ($|\Delta_{\widehat{\phi}_n}|$, $|\Delta_{\widehat{\mu}_n}|$) suggests there is no evidence of a consistency between the misestimation of of SPEEC from MLE of effect size parameters and sample size parameters. However, there was a strong and statistically significant negative correlation between the parameters of the effect size distribution ($|\Delta_{\widehat{\mu}_d}|$, $|\Delta_{\widehat{\sigma}^2_d}|$) and the publication bias parameter $\epbs$ such that larger divergences between MLE and SPEEC of the distributional parameters were associated with lower predicted values of the publication bias parameter. Because, as argued previously, $\epbs$ should in theory equal exactly 1, this negative correlation can be interpreted as a consistency in the misestimation of the effect size parameter of SPEEC from MLE and the misestimation of the publication bias parameter $\epbs$.

## Which Factors Drive the Parameter Misestimation in SPEEC?

The systematic discrepancy between MLE and SPEEC for the distribution parameters, together with the consistency in the misestimation of the effect size parameters and the publication bias parameter, begs the question of what factors are responsible for the parameter misestimation of the SPEEC method.

In this regard, no evidence was found that the sample size $k$ of the RRRs was associated with the misestimation of the distributional parameters of SPEEC from MLE. However, strong positive correlations were observed between the misestimation of SPEEC from MLE in the effect size distribution parameters ($|\Delta_{\widehat{\mu}d}|$, $|\Delta_{\widehat{\sigma}^2_d}|$) and between-study heterogeneity $\widehat{\tau}$. Additionally, a medium negative correlation was observed between the publication bias parameter $\epbs$ and between-study heterogeneity $\widehat{\tau}$. This indicates that increasing observed heterogenity $\widehat{\tau}$ is associated with larger misestimation of distributional parameter of SPEEC from MLE and larger misestimation of the publication bias parameter $\epbs$. Overall, these results highlight the potential significance of between-study heterogeneity in influencing parameter misestimation.

This is plausible from the perspective that the simulation framework of SPEEC currently assumes a fixed-effect meta-analytical model, where the only source of effect size variation is attributable to sampling error. Both the classical meta-analyses and the RRRs of the empirical data used for the proof of concept displayed moderate to large levels of between-study heterogeneity [@linden_heterogeneity_2021]. Thus, the the empirical data displayed an additional level of effect size variation that could not be adequately modeled in the SPEEC method due to sampling error alone. Especially due the definition of the loss function $D_{\text{KL}}$ as a statistical distance between kernel densities from empirical and simulated data, parameters may be erroneously adjusted in the presence of heterogeneity to minimize the loss function. 

This could be one potential explanation for the associated predicted decrease in $\epbs$ for high heterogeneity $\widehat{\tau}$, as more severe publication bias implies that the nonsignificant studies, that are likely to have effect sizes close to zero, are censored, thus artificially increasing the overall variance to account for heterogeneity in the minimzation of $D_{\text{KL}}$. Furthermore, the same line of reasoning could also account for the positive relationship between $| \Delta_{\widehat{\sigma}^2_d} |$ and $\sigma^2_d$, as the overestimation of $\sigma^2_d$ by SPEEC compared to MLE increases the overall variability of the effect size distribution to seamingly capture heterogeneity.


In summary, the challenges encountered by the current version of the SPEEC method, which are likely attributable to between-study heterogeneity, are parallel to those faced by other statistical techniques assuming a fixed-effects meta-analytical model, such as *p*-uniform and *p*-curve analysis [@simonsohn_p-curve_2014; @van_assen_meta-analysis_2015]. These methods tend to exhibit poor performance in the presence of substantial heterogeneity, resulting in an overestimation of the true effect size under such conditions [@mcshane_adjusting_2016; @carter_correcting_2019; @van_aert_conducting_2016]. This aligns with the positive correlation observed between $|\Delta_{\widehat{\mu}_d}|$ and $\widehat{\tau}$, suggesting that an increase heterogeneity is associated with a greater misestimation of SPEEC from MLE for the mean parameter $\mu_d$ of the effect size distribution.

## Limitations

In addition to the already discussed likely challenges that SPEEC faces due to between-study heterogeneity there are several other limitations.

these may be subdivided into objections to the SPEEC method itself and limitations of the study design.

Objections to the SPEEC method itself
- other than the observed parameter estimation challenges that are likely due to heterogeneity:
- altough in comparison to other common methods, an explicit generative publication bias model was assumed, real life data models and selection models of publication bias are far more complicated [@mcshane_adjusting_2016]: studies often have a multiple dependent effects of interest (selection likely to be based on properties of these multiple dependent effects jointly), QRPs also present which interacts with publication bias [@friese_p-hacking_2020] -> still kind of unrealistic model
- no quantification of uncertainty of the parameter estimation of SPEEC -> what missing confidence in the publication bias-corrected meta-analytical effect size and the exent of publication bias


Limitations of the study
  - Study designed as a proof of concept -> only a preliminary evalution of the SPEEC method
  - Need large simulation study

## Directions for Future Research

1. Further development of the SPEEC method
   - Given that between-study heterogeneity is very common in psychology and other fields [@linden_heterogeneity_2021; @van_erp_estimates_2017; @higgins_commentary_2008] -> importance of incorporting heterogeneity parameter in the simulation framework -> einordnung der ergebnise -> sonst parameter schÃ¤tzung nicht gut
   - Consider sample size planning, p-hacking etc.
2. Comprehensive Evaluation of the SPEEC method (simulation study)
   - Comprehensive simulation study
   - How does adapted SPEEC perform under various conditions -> heterogeneity, sample size, true effect size, degree of publication bias, (additional) *p*-hacking

## Conclusion

