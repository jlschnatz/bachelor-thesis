
# General Discussion

The objective of the present thesis was to introduce a flexible simulation-based framework to assess the extent of publication bias and estimate corrected effect sizes based on the joint distribution of effect size and sample size in the presence of publication bias (SPEEC). In a proof-of-concept study, the viability of the SPEEC method was evaluated based on four theoretically derived hypotheses, which should be corroborated by empirical data encompassing both classical meta-analyses and publication bias-free registered replication reports (RRR) if the method works in principle. The confirmatory analyses revealed that, while three out of the four predictions were statistically significant, the effect sizes for these hypotheses were weak. Additionally, no evidence supported the fourth hypothesis, pointing to potential issues with the parameter estimation in the SPEEC method.

To further diagnose these potential parameter estimation challenges, five exploratory diagnostic questions were derived using the subset of publication bias-free RRRs to compare the distributional parameters estimated using SPEEC to those estimated using MLE. Additionally, it was also examined how these divergences between SPEEC and MLE are associated with the publication bias parameter $\pbs$ and uncertainty-related factors such as the number of individual replication studies within each RRR $k$ and between-study heterogeneity $\tau$. Overall, this analysis aimed to quantify the extent and consistency of misestimation in SPEEC compared to MLE (question 1-3) and to identify potential root causes of the parameter estimation issues (question 4-5).

## Extent and Consistency of Misestimation of SPEEC Parameters

Regarding the first three exploratory diagnostic questions, it was found that, except for the mean $\mu_d$ of the effect size distribution, there were systematic divergences between SPEEC and MLE in the parameter estimation. This misestimation of SPEEC from MLE was not constant across the parameter space of the MLE estimates, displaying nonlinear functional forms and substantial heteroscedasticity. 

The correlational analyses indicated consistency in the misestimation of SPEEC compared to MLE for the mean $|\Delta_{\widehat{\mu}_d}|$ and variance parameter $|\Delta_{\widehat{\sigma}^2_d}|$ of the effect size distribution. In other words, an increase in the absolute divergence between SPEEC and MLE in one parameter was associated with an increase in the absolute divergence in the other parameter. The absence of any substantial (and significant) correlations between the divergences of SPEEC and MLE for effect size distribution parameters ($|\Delta_{\widehat{\mu}_d}|$, $|\Delta_{\widehat{\sigma}^2_d}|$) and sample size distribution parameters ($|\Delta_{\widehat{\phi}_n}|$, $|\Delta_{\widehat{\mu}_n}|$) suggests that there is no evidence of consistency between the misestimation of SPEEC from MLE regarding effect size and sample size parameters. However, there was a strong and statistically significant negative correlation between the parameters of the effect size distribution ($|\Delta_{\widehat{\mu}_d}|$, $|\Delta_{\widehat{\sigma}^2_d}|$) and the publication bias parameter $\epbs$ such that larger divergences between MLE and SPEEC of the distributional parameters were associated with lower predicted values of the publication bias parameter. Because, as argued previously, $\epbs$ should, in theory, equal exactly 1, this negative correlation can be interpreted as consistency in the misestimation of the effect size parameter of SPEEC from MLE and the misestimation of the publication bias parameter $\epbs$.

## Which Factors Drive the Parameter Misestimation in SPEEC?

The systematic discrepancy between MLE and SPEEC for the distribution parameters, together with the consistency in the misestimation of the effect size parameters and the publication bias parameter, begs the question of what factors are responsible for the parameter misestimation of the SPEEC method.

In this regard, no evidence was found that the sample size $k$ of the RRRs was associated with the misestimation of the distributional parameters of SPEEC from MLE. However, strong positive correlations were observed between the misestimation of SPEEC from MLE in the effect size distribution parameters ($|\Delta_{\widehat{\mu}d}|$, $|\Delta_{\widehat{\sigma}^2_d}|$) and between-study heterogeneity $\widehat{\tau}$. Additionally, a medium negative correlation was observed between the publication bias parameter $\epbs$ and between-study heterogeneity $\widehat{\tau}$. This indicates that increasing observed heterogeneity $\widehat{\tau}$ was associated with a larger misestimation of the distributional parameter of SPEEC from MLE and a larger misestimation of the publication bias parameter $\epbs$. These results highlight the potential significance of between-study heterogeneity in influencing parameter misestimation.

This is plausible from the perspective that the simulation framework of SPEEC currently assumes a fixed-effect meta-analytical model, where the only source of effect size variation is sampling error. Both classical meta-analyses and RRRs of the empirical data used for the proof-of-concept displayed moderate to large levels of between-study heterogeneity [@linden_heterogeneity_2021]. Thus, the empirical data‘s additional level of effect size variation could not be adequately modeled in the SPEEC method due to sampling error alone. In particular, because of the definition of the loss function $D_{\text{KL}}$ as a statistical distance between the kernel densities from the empirical and simulated data, parameters may be erroneously adjusted in the presence of heterogeneity to minimise the loss function. 

This could be one potential explanation for the associated predicted decrease in $\epbs$ for high heterogeneity $\widehat{\tau}$, as more severe publication bias implies that the nonsignificant studies that are likely to have effect sizes close to zero are censored, thus artificially increasing the overall variance to account for heterogeneity in the minimisation of $D_{\text{KL}}$. Furthermore, the same line of reasoning could also account for the positive relationship between $| \Delta_{\widehat{\sigma}^2_d} |$ and $\sigma^2_d$, as the overestimation of $\sigma^2_d$ by SPEEC compared to MLE increases the overall variability of the effect size distribution to seemingly capture heterogeneity.

In summary, the challenges encountered by the current version of the SPEEC method, which are likely attributable to between-study heterogeneity, are parallel to those faced by other statistical techniques assuming a fixed-effect meta-analytical model, such as *p*-uniform and *p*-curve analysis [@simonsohn_p-curve_2014; @van_assen_meta-analysis_2015]. These methods tend to perform poorly in the presence of substantial heterogeneity, resulting in an overestimation of the true effect size under such conditions [@mcshane_adjusting_2016; @carter_correcting_2019; @van_aert_conducting_2016]. This aligns with the positive correlation observed between $|\Delta_{\widehat{\mu}_d}|$ and $\widehat{\tau}$, suggesting that an increase in heterogeneity was associated with a greater misestimation of SPEEC from MLE for the mean parameter $\mu_d$ of the effect size distribution.

## Limitations

Besides the previously discussed challenges in the parameter estimation of SPEEC, which are likely to result from heterogeneity, the present thesis has additional limitations that should be considered. These may be subdivided into objections against the SPEEC method itself and study design constraints.

The first major limitation of the SPEEC method is the lack of uncertainty quantification in estimating the parameters in SPEEC. This lack of quantification of parameter uncertainty undermines the ability to assess the confidence of these estimates accurately [@lele_how_2020]. As an illustration, one would have varying degrees of confidence in the estimated extent of publication bias $\epbs$ and the corrected meta-analytical effect size $\mu_d$ for a small-scale meta-analysis with a sample size of $k=20$ in comparison to a large-scale meta-analysis with a sample size of $k=500$. This inability can be considered inferior to other common methods to assess publication bias that yield confidence estimates.

Secondly, while an explicit generative publication bias model in SPEEC may be seen as an advancement compared to other methods lacking such assumptions, the model's assumptions remain oversimplistic. Real-world scenarios involve more intricate data models and selection mechanisms. Studies often encompass multiple dependent effects of interest, with selection likely based on properties of these effects taken jointly [@mcshane_adjusting_2016]. In addition, questionable research practices in existing scientific research can further complicate the data and selection models due to their interaction with publication bias [@friese_p-hacking_2020].

The constraints regarding the study design relate to the study‘s conception as proof of concept. Although the investigation of the theoretically derived hypotheses in the confirmatory analyses yielded important insights into potential parameter estimation challenges, and diagnostic exploratory findings underscored the potential significance of heterogeneity in explaining these challenges, the assessment was limited in its capacity to offer a holistic understanding of SPEEC‘s viability across various conditions. For this, large-scale simulation studies are necessary because the parameters of interest are known and manipulable [@morris_using_2019].

## Directions for Future Research

Considering the results of both the confirmatory and the exploratory diagnostic analyses, there is a call for further investigations in at least two directions. These encompass the further development of the SPEEC method and a comprehensive assessment of SPEEC within a simulation setting.

Regarding the former, considering the likely contribution of heterogeneity to the parameter misestimation in the investigated empirical data, as well as its common prevalence across meta-analyses [@linden_heterogeneity_2021; @van_erp_estimates_2017; @higgins_commentary_2008], highlights the importance of incorporating a heterogeneity parameter in the simulation framework of SPEEC. Failure to account for heterogeneity could otherwise potentially jeopardize the validity of SPEEC in settings where heterogeneity is present. Additionally, as briefly touched upon in the introduction, there exist other factors that influence the joint distribution of effect size and sample size, including *sample size planning*, where researchers plan sample sizes based on predicated effect sizes [@linden_publication_2024] and questionable research practices such as *p*-hacking, which can interact with publication bias [@friese_p-hacking_2020]. Incorporating these factors into the simulation framework in future research could lead to more accurate modeling of publication bias.

A comprehensive assessment of SPEEC within a simulation setting should focus on evaluating the accuracy of parameter estimation of SPEEC under various conditions commonly encountered in real-world meta-analytical data and that have been considered in previous simulation studies that assessed other publication bias detection methods. Key factors to consider include the extent of publication bias ($\pbs$), true effect size ($\mu_d$), amount of heterogeneity ($\tau$),  the number of primary studies $k$ within the meta-analysis and questionable research practices such as *p*-hacking [@carter_correcting_2019; @van_aert_publication_2019; @renkewitz_how_2019; @mcshane_adjusting_2016; @schneck_examining_2017].

## Conclusion

In conclusion, this thesis introduced a novel and flexible framework for assessing publication bias and correcting meta-analytic effect sizes in the presence of publication bias based on the joint distribution of effect size and sample size. This framework includes explicit assumptions about the generative processes of publication bias and is adaptable to incorporating various factors that may be valuable for modeling and assessing publication bias in meta-analyses. However, the results of the proof-of-concept study have demonstrated that adjustments to the simulation framework to incorporate heterogeneity are required before using the SPEEC method in real-world applications. Finally, we seek to stimulate further research to advance the development of SPEEC by providing concrete recommendations on potentially valuable adaptations of SPEEC and factors to consider in a comprehensive evaluation of SPEEC.